{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats and Dogs Classification with Augmentation and Dropout.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smar2009/Phishguard-AI/blob/master/Cats%20and%20Dogs%20Classification%20with%20Augmentation%20and%20Dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09e4UMEGsFlU"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-_OO-M_sEz2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkrgVHiIz1WI"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAKMkAWVYsTT"
      },
      "source": [
        "url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=url, extract=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HUdyXumZpov"
      },
      "source": [
        "The dataset we have downloaded has the following directory structure.\n",
        "\n",
        "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
        "<b>cats_and_dogs_filtered</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...]\n",
        "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ <b>validation</b>\n",
        "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...]\n",
        "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2b9b2GD6ccB"
      },
      "source": [
        "## List the directories with the following terminal command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5_-I49IgWqV"
      },
      "source": [
        "import os\n",
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "!find $zip_dir_base -type d -print"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMyuj-ic6HpU"
      },
      "source": [
        "## Assign Directory Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-i9ElfWe_0H"
      },
      "source": [
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat/dog pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat/dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSc_Y5GD6NhW"
      },
      "source": [
        "## Print Filenames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ymdG8rmUMz"
      },
      "source": [
        "train_cat_fnames = os.listdir( train_cats_dir )\n",
        "train_dog_fnames = os.listdir( train_dogs_dir )\n",
        "\n",
        "print(train_cat_fnames[:10])\n",
        "print(train_dog_fnames[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paY4x__p6Q1t"
      },
      "source": [
        "## Print number of Training and Validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G0w8wudmdNI"
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images :', len(os.listdir(      train_cats_dir ) ))\n",
        "print('total training dog images :', len(os.listdir(      train_dogs_dir ) ))\n",
        "\n",
        "print('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\n",
        "print('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7ZgQF1uDiOL"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHmNYxFSDd5Q"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "IMG_SHAPE = 150\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "# --------------------\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(IMG_SHAPE, IMG_SHAPE))\n",
        "\n",
        "# --------------------\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "# --------------------\n",
        "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=BATCH_SIZE,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (IMG_SHAPE, IMG_SHAPE))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdiZGaZZq1cf"
      },
      "source": [
        "## Visualizing Training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw9sQts4rDWH"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAKyTi75rA_S"
      },
      "source": [
        "sample_training_images, _ = next(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbgkJATUrFnl"
      },
      "source": [
        "plotImages(sample_training_images[:5])  # Plot images 0-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcZb6ELl1y-P"
      },
      "source": [
        "# Image Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsbTyxbp15He"
      },
      "source": [
        "## Flipping the image horizontally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I-t5R-h105C"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE,IMG_SHAPE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLCqWVA-2TOW"
      },
      "source": [
        "augmented_images = [train_generator[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm0ohFXH2Zft"
      },
      "source": [
        "## Rotating the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKPfJiUc2Xe4"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=45)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE, IMG_SHAPE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHiKwTte2dzk"
      },
      "source": [
        "augmented_images = [train_generator[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os7RIq4g2j9e"
      },
      "source": [
        "## Applying Zoom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWeTe_Gv2jTb"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE, IMG_SHAPE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDlxtZ9S2q4x"
      },
      "source": [
        "augmented_images = [train_generator[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ytqcl632zT4"
      },
      "source": [
        "## Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkFwE0An2xOA"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc-9X2TL25uJ"
      },
      "source": [
        "augmented_images = [train_generator[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H45L6NlLznEr"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzCuTnsuD1oz"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), padding = 'same', activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding = 'same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding = 'same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Dropout\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Our last layer (our classifier) consists of a Dense layer with 2 output units and a softmax activation function\n",
        "    # tf.keras.layers.Dense(2, activation='softmax')\n",
        "    # Another popular approach when working with binary classification problems, is to use a classifier that consists of a Dense layer with 1 output unit and a sigmoid activation function\n",
        "    # It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irOi9dPieeQR"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC0ci1y3epoY"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YEC_0xLm4Cr"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPDyARoFmyIO"
      },
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "                              epochs=EPOCHS,\n",
        "                              validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))),\n",
        "                              verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mxcP3sLuM_-"
      },
      "source": [
        "# Visualizing results of the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjhFM4Rin3e4"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "#plt.savefig('./foo.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0N1-o6QiSzY"
      },
      "source": [
        "# Prediction using the Model\n",
        "\n",
        "Let's now take a look at actually running a prediction using the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyTT3mJ7rjmj"
      },
      "source": [
        "test_images, test_labels = next(validation_generator)\n",
        "classes = model.predict(test_images, 10)\n",
        "classes = classes.flatten()\n",
        "print(classes)\n",
        "print(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfzmIljgh0tu"
      },
      "source": [
        "fig, axes = plt.subplots(4, 5, figsize=(20,20))\n",
        "axes = axes.flatten()\n",
        "i = 0\n",
        "for img, ax in zip(test_images, axes):\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    color = 'blue'\n",
        "    if round(classes[i]) != test_labels[i] :\n",
        "        color = 'red'\n",
        "    if classes[i]>0.5:\n",
        "        ax.set_title(\"Dog\",fontdict = {'size' : 20, 'color' : color});\n",
        "    else :\n",
        "        ax.set_title(\"Cat\",fontdict = {'size' : 20, 'color' : color});\n",
        "    i+=1\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}